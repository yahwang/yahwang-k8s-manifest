##
## Copyright (C) 2024 Dremio
##
## Licensed under the Apache License, Version 2.0 (the "License");
## you may not use this file except in compliance with the License.
## You may obtain a copy of the License at
##
## http://www.apache.org/licenses/LICENSE-2.0
##
## Unless required by applicable law or agreed to in writing, software
## distributed under the License is distributed on an "AS IS" BASIS,
## WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
## See the License for the specific language governing permissions and
## limitations under the License.
##

# -- The number of replicas to deploy (horizontal scaling).
# Beware that replicas are stateless; don't set this number > 1 when using IN_MEMORY or ROCKSDB version store types.
replicaCount: 1

image:
  # -- The image repository to pull from.
  repository: ghcr.io/projectnessie/nessie
  # -- The image pull policy.
  pullPolicy: IfNotPresent
  # -- Overrides the image tag whose default is the chart version.
  tag: ""
  # -- The path to the directory where the application.properties file should be mounted.
  configDir: /deployments/config

# -- References to secrets in the same namespace to use for pulling any of the images used by this
# chart. Each entry is a LocalObjectReference to an existing secret in the namespace. The secret
# must contain a .dockerconfigjson key with a base64-encoded Docker configuration file. See
# https://kubernetes.io/docs/tasks/configure-pod-container/pull-image-private-registry/ for more
# information.
imagePullSecrets: []
#  - name: registry-creds

# -- Logging configuration.
log:
  # -- The log level of the root category, which is used as the default log level for all categories.
  level: INFO
  # -- Configuration for the console appender.
  console:
    # -- Whether to enable the console appender.
    enabled: true
    # -- The log level of the console appender.
    threshold: ALL
    # -- Whether to log in JSON format.
    json: false
    # -- The log format to use. Ignored if JSON format is enabled. See
    # https://quarkus.io/guides/logging#logging-format for details.
    format: "%d{yyyy-MM-dd HH:mm:ss,SSS} %-5p [%c{3.}] (%t) %s%e%n"
  # -- Configuration for the file appender.
  file:
    # -- Whether to enable the file appender.
    enabled: false
    # -- The log level of the file appender.
    threshold: ALL
    # -- Whether to log in JSON format.
    json: false
    # -- The log format to use. Ignored if JSON format is enabled. See
    # https://quarkus.io/guides/logging#logging-format for details.
    format: "%d{yyyy-MM-dd HH:mm:ss,SSS} %h %N[%i] %-5p [%X{traceId},%X{spanId},%X{sampled}] [%c{3.}] (%t) %s%e%n"
    # -- The local directory where log files are stored. The persistent volume claim will be mounted
    # here.
    logsDir: /deployments/logs
    # -- The log file name.
    fileName: nessie.log
    # -- Log rotation configuration.
    rotation:
      # -- The maximum size of the log file before it is rotated. Should be expressed as a Kubernetes quantity.
      maxFileSize: 100Mi
      # -- The maximum number of backup files to keep.
      maxBackupIndex: 5
      # -- An optional suffix to append to the rotated log files. If present, the rotated log files
      # will be grouped in time buckets, and each bucket will contain at most maxBackupIndex files.
      # The suffix must be in a date-time format that is understood by DateTimeFormatter. If the
      # suffix ends with .gz or .zip, the rotated files will also be compressed using the
      # corresponding algorithm.
      fileSuffix: ~  # .yyyy-MM-dd.gz
    # -- The log storage configuration. A persistent volume claim will be created using these
    # settings.
    storage:
      # -- The storage class name of the persistent volume claim to create.
      className: longhorn
      # -- The size of the persistent volume claim to create.
      size: 1Gi
      # -- Labels to add to the persistent volume claim spec selector; a persistent volume with
      # matching labels must exist. Leave empty if using dynamic provisioning.
      selectorLabels: {}
        # app.kubernetes.io/name: nessie
        # app.kubernetes.io/instance: RELEASE-NAME
  # -- Configuration for the Sentry appender. See https://sentry.io and
  # https://docs.quarkiverse.io/quarkus-logging-sentry/dev for more information.
  sentry:
    # -- Whether to enable the Sentry appender.
    enabled: false
    # -- The Sentry DSN. Required.
    dsn: ~  # "https://abcd@sentry.io/1234"
    # -- The log level of the Sentry appender.
    level: ERROR
    # -- The environment to report to Sentry. Optional.
    environment: ~
    # -- The release version to report to Sentry. Optional.
    release: ~
    # -- Package prefixes that belong to your application.
    inAppPackages:
    - org.projectnessie
  # -- Configuration for specific log categories.
  categories:
    org.projectnessie: INFO
    # Useful to debug configuration issues:
    # io.smallrye.config: DEBUG

# -- Which type of version store to use: IN_MEMORY, ROCKSDB, DYNAMODB2, MONGODB2, CASSANDRA2, JDBC2, BIGTABLE.
# Note: the version store type JDBC is deprecated, please use the Nessie Server Admin Tool to migrate to JDBC2.
# Note: the version store type CASSANDRA is deprecated, please use the Nessie Server Admin Tool to migrate to CASSANDRA2.
# Note: the version store type DYNAMODB is deprecated, please use the Nessie Server Admin Tool to migrate to DYNAMODB2.
# Note: the version store type MONGODB is deprecated, please use the Nessie Server Admin Tool to migrate to MONGODB2.
versionStoreType: JDBC2

# JDBC datasource settings. Only required when using JDBC version store type; ignored otherwise.
jdbc:
  # -- The JDBC connection string. If you are using Nessie OSS images, then only
  # PostgreSQL, MariaDB and MySQL URLs are supported. Check your JDBC driver documentation
  # for the correct URL format.
  jdbcUrl: jdbc:postgresql://common-postgres-rw.common.svc:5432/nessie?currentSchema=public
  secret:
    # -- The secret name to pull datasource credentials from.
    name: common-postgres-superuser
    # -- The secret key storing the datasource username.
    username: username
    # -- The secret key storing the datasource password.
    password: password

# -- The Nessie catalog server configuration.
catalog:

  # -- Whether to enable the REST catalog service.
  enabled: true

  # -- Iceberg catalog settings.
  iceberg:

    # -- The default warehouse name. Required. This is just a symbolic name; it must refer to a
    # declared warehouse below.
    defaultWarehouse: nessie-warehouse  # warehouse1

    # -- Iceberg config defaults applicable to all clients and warehouses. Any properties that are
    # common to all iceberg clients should be included here. They will be passed to all clients on
    # all warehouses as config defaults. These defaults can be overridden on a per-warehouse basis,
    # see below.
    configDefaults: {}
    # io-impl: org.apache.iceberg.hadoop.HadoopFileIO

    # -- Iceberg config overrides applicable to all clients and warehouses. Any properties that are
    # common to all iceberg clients should be included here. They will be passed to all clients on
    # all warehouses as config overrides. These overrides can be overridden on a per-warehouse
    # basis, see below.
    configOverrides: {}
    # s3.acl: public-read-write

    # -- Iceberg warehouses. Each warehouse is a location where Iceberg tables are stored. Each
    # warehouse has a name, a location, and optional config defaults and overrides. At least one
    # warehouse must be defined.
    warehouses:
      # -- Symbolic name of the warehouse. Required.
    - name: nessie-warehouse  # warehouse1
      # -- Location of the warehouse. Required. Used to determine the base location of a table.
      # Scheme must be either s3 (Amazon S3), gs (Google GCS) or abfs / abfss (Azure ADLS). Storage
      # properties for each location can be defined below.
      location: s3://nessie-warehouse/
      # -- Iceberg config defaults specific to this warehouse. They override any defaults specified
      # above in catalog.iceberg.configDefaults.
      configDefaults: {}
      # -- Iceberg config overrides specific to this warehouse. They override any defaults specified
      # above in catalog.iceberg.configOverrides.
      configOverrides: {}
    # In rare cases it might be legit to turn off the object-stores readiness check.
    objectStoresHealthCheckEnabled: true

  # -- Catalog storage settings.
  storage:
    # -- Interval after which a request is retried when Storage responds with some "retry later"
    # error. Must be a valid ISO duration.
    retryAfter: ~

    s3:

      # Global S3 settings. Can be overridden on a per-bucket basis below.
      defaultOptions:
        # -- DNS name of the region, required for AWS.
        region: ap-northeast-2  # us-west-2
        # -- Endpoint URI, required for private clouds. Optional; if not provided, the default is
        # used.
        endpoint: http://minio-api.172.30.1.101.nip.io:80  # "https://bucket1.s3.amazonaws.com"
        # -- Endpoint URI, required for private clouds. Optional; if not provided, the default is
        # used. If the endpoint URIs for the Nessie server and clients differ, this one defines the
        # endpoint used for the Nessie server.
        externalEndpoint: ~
        # -- Whether to use path-style access. Optional; if not provided, the default is used. If
        # true, path-style access will be used, as in: https://<domain>/<bucket>. If false, a
        # virtual-hosted style will be used instead, as in: https://<bucket>.<domain>.
        pathStyleAccess: true
        # -- AWS Access point for this bucket. Access points can be used to perform S3 operations by
        # specifying a mapping of bucket to access points. This is useful for multi-region access,
        # cross-region access, disaster recovery, etc. See
        # https://docs.aws.amazon.com/AmazonS3/latest/userguide/using-access-points.html.
        accessPoint: ~
        # -- Authorize cross-region calls when contacting an access point. The default is false.
        allowCrossRegionAccessPoint: ~
        # -- Controls the authentication mode for the Catalog server. Valid values are:
        # - APPLICATION_GLOBAL: Use the default AWS credentials provider chain.
        # - STATIC: Static credentials provided through the accessKeySecret option.
        # The default is STATIC.
        authType: STATIC  # STATIC
        # --Optional parameter to disable S3 request signing. Default is to enable S3 request signing.
        requestSigningEnabled: false  # true
        # -- The STS endpoint. Optional; if not provided, the default is used. This parameter must
        # be set if the cloud provider is not AMAZON and the catalog is configured to use S3
        # sessions (e.g. to use the "assume role" functionality).
        stsEndpoint: ~  # "https://sts.amazonaws.com"

        # -- AWS credentials. Required when serverAuthenticationMode is STATIC.
        accessKeySecret:
          # -- The secret name to pull AWS credentials from.
          name: minio-secret
          # -- The secret key storing the AWS secret key id.
          awsAccessKeyId: AWS_ACCESS_KEY_ID
          # -- The secret key storing the AWS secret access key.
          awsSecretAccessKey: AWS_SECRET_ACCESS_KEY

      # -- Per-bucket S3 settings. Override the general settings above.
      buckets: []
      # - name: bucket1
      #   authority: bucket1
      #   pathPrefix: path/in/the/bucket
      #   endpoint: "https://bucket1.s3.amazonaws.com"
      #   accessKeySecret:
      #     name: awscreds
      #     awsAccessKeyId: aws_access_key_id
      #     awsSecretAccessKey: aws_secret_access_key

      # -- S3 transport settings. Not overridable on a per-bucket basis.
      transport:
        # -- Override the default maximum number of pooled connections.
        maxHttpConnections: ~
        # -- Override the default connection read timeout. Must be a valid ISO duration.
        readTimeout: ~
        # -- Override the default TCP connect timeout. Must be a valid ISO duration.
        connectTimeout: ~
        # -- Override default connection acquisition timeout. This is the time a request will wait
        # for a connection from the pool. Must be a valid ISO duration.
        connectionAcquisitionTimeout: ~
        # -- Override default max idle time of a pooled connection. Must be a valid ISO duration.
        connectionMaxIdleTime: ~
        # -- Override default time-time of a pooled connection. Must be a valid ISO duration.
        connectionTimeToLive: ~
        # -- Override default behavior whether to expect an HTTP/100-Continue. Must be a valid ISO
        # duration.
        expectContinueEnabled: ~

      sessionCredentials:
        # -- The time period to subtract from the S3 session credentials (assumed role credentials)
        # expiry time to define the time when those credentials become eligible for refreshing.
        # Not overridable on a per-bucket basis. The default is PT5M (5 minutes).
        sessionCredentialRefreshGracePeriod: ~  # PT5M
        # -- Maximum number of entries to keep in the session credentials cache (assumed role
        # credentials). Not overridable on a per-bucket basis. The default is 1000.
        sessionCredentialCacheMaxEntries: ~  # 1000
        # -- Maximum number of entries to keep in the STS clients cache. Not overridable on a
        # per-bucket basis. The default is 50.
        stsClientsCacheMaxEntries: ~  # 50

# -- Advanced configuration.
# You can pass here any valid Nessie or Quarkus configuration property.
# Any property that is defined here takes precedence over all the other configuration values generated by this chart.
# Properties can be passed "flattened" or as nested YAML objects (see examples below).
advancedConfig:
  {}
# Nessie version store settings
# -----------------------------
#
#  See description of the various cache size parameters and their defaults.
#
#  nessie.version.store.persist.cache-capacity-mb: (defaults to fractional size, based on max-heap size)
#  nessie.version.store.persist.cache-capacity-fraction-of-heap: 0.7
#  nessie.version.store.persist.cache-capacity-fraction-adjust-mb: 256
#  nessie.version.store.persist.cache-capacity-fraction-min-size-mb: 64
#
#  nessie.server.default-branch: my-branch
#
#  nessie.version.store.persist.repository-id: my-repository
#
# Reverse Proxy Settings
# ----------------------
#
# These config options are mentioned only for documentation purposes. Consult the
# Quarkus documentation for "Running behind a reverse proxy" and configure those
# depending on your actual needs.
#
# See https://quarkus.io/guides/http-reference#reverse-proxy
#
# Do NOT enable these option unless your reverse proxy (for example istio or nginx)
# is properly setup to set these headers but also filter those from incoming requests.
#
#  quarkus:
#   http:
#     proxy:
#       proxy-address-forwarding: "true"
#       allow-x-forwarded: "true"
#       enable-forwarded-host: "true"
#       enable-forwarded-prefix: "true"
#       trusted-proxies: "127.0.0.1"

# -- Advanced configuration via Environment Variables.
# Extra environment variables to add to the Nessie server container.
# You can pass here any valid EnvVar object:
# https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.27/#envvar-v1-core
# This can be useful to get configuration values from Kubernetes secrets or config maps.
extraEnv:
  []
#  - name: QUARKUS_MONGODB_APPLICATION_NAME
#    value: my-app
#  - name: QUARKUS_MONGODB_TLS
#    valueFrom:
#      configMapKeyRef:
#        name: mongodb-config
#        key: tls

authentication:
  # -- Specifies whether authentication for the nessie server should be enabled.
  enabled: false
  # -- Sets the base URL of the OpenID Connect (OIDC) server. Required if authentication is enabled (unless local token introspection is enforced through advanced configuration).
  oidcAuthServerUrl: ~  # http://example.com:8080/auth/realms/master
  # -- Set the OIDC client ID. If Nessie must contact the OIDC server, this is the client ID that will be used to identify the application.
  oidcClientId: nessie
  # -- Set the OIDC client secret. Whether the client secret is required depends on the OIDC server configuration.
  # For Keycloak, the client secret is generally not required as the returned tokens can be introspected locally by Nessie.
  # If token introspection requires a round-trip to the OIDC server, the client secret is required.
  oidcClientSecret: {}
#    name: nessie-oidc-creds
#    key: client-secret

authorization:
  # -- Specifies whether authorization for the nessie server should be enabled.
  enabled: false
  # -- The authorization rules when authorization.enabled=true. Example rules can be found at https://projectnessie.org/features/metadata_authorization/#authorization-rules
  rules:
    {}
    # allowViewingBranch: op=='VIEW_REFERENCE' && role.startsWith('test_user') && ref.startsWith('allowedBranch')
    # allowCommits: op=='COMMIT_CHANGE_AGAINST_REFERENCE' && role.startsWith('test_user') && ref.startsWith('allowedBranch')

tracing:
  # -- Specifies whether tracing for the nessie server should be enabled.
  enabled: false
  # -- The collector endpoint URL to connect to (required).
  # The endpoint URL must have either the http:// or the https:// scheme.
  # The collector must talk the OpenTelemetry protocol (OTLP) and the port must be its gRPC port (by default 4317).
  # See https://quarkus.io/guides/opentelemetry for more information.
  endpoint: "http://otlp-collector:4317"
  # -- Which requests should be sampled. Valid values are: "all", "none", or a ratio between 0.0 and
  # "1.0d" (inclusive). E.g. "0.5d" means that 50% of the requests will be sampled.
  sample: "1.0d"
  # -- Resource attributes to identify the nessie service among other tracing sources.
  # See https://opentelemetry.io/docs/reference/specification/resource/semantic_conventions/#service.
  # If left empty, traces will be attached to a service named "Nessie"; to change this, provide a service.name attribute here.
  attributes:
    {}
    # service.name: my-nessie

metrics:
  # -- Specifies whether metrics for the nessie server should be enabled.
  enabled: true
  # -- Additional tags (dimensional labels) to add to the metrics.
  tags:
    {}
    # service: nessie
    # environment: production

serviceMonitor:
  # -- Specifies whether a ServiceMonitor for Prometheus operator should be created.
  enabled: true
  # -- The scrape interval; leave empty to let Prometheus decide. Must be a valid duration, e.g. 1d, 1h30m, 5m, 10s.
  interval: ""
  # -- Labels for the created ServiceMonitor so that Prometheus operator can properly pick it up.
  labels:
    {}
    # release: prometheus
  # -- Relabeling rules to apply to metrics. Ref https://prometheus.io/docs/prometheus/latest/configuration/configuration/#relabel_config.
  metricRelabelings: []
    # - source_labels: [ __meta_kubernetes_namespace ]
    #   separator: ;
    #   regex: (.*)
    #   target_label: namespace
    #   replacement: $1
    #   action: replace

serviceAccount:
  # -- Specifies whether a service account should be created.
  create: true
  # -- Annotations to add to the service account.
  annotations: {}
  # -- The name of the service account to use.
  # If not set and create is true, a name is generated using the fullname template.
  name: ""

# -- Annotations to apply to nessie pods.
podAnnotations: {}

# -- Additional Labels to apply to nessie pods.
podLabels: {}

# -- Additional Labels to apply to nessie configmap.
configMapLabels: {}

# -- Additional Annotations to apply to nessie configmap.
configMapAnnotations: {}

# -- Security context for the nessie pod. See https://kubernetes.io/docs/tasks/configure-pod-container/security-context/.
podSecurityContext:
  # GID 10001 is compatible with Nessie OSS default images starting with 0.95.1; change this if you
  # are using a different image.
  fsGroup: 10001
  seccompProfile:
    type: RuntimeDefault

# -- Security context for the nessie container. See https://kubernetes.io/docs/tasks/configure-pod-container/security-context/.
securityContext:
  # UID 10000 and GID 10001 are compatible with Nessie OSS default images starting with 0.95.1;
  # change this if you are using a different image.
  runAsUser: 10000
  runAsGroup: 10001
  runAsNonRoot: true
  privileged: false
  allowPrivilegeEscalation: false
  readOnlyRootFilesystem: true
  capabilities:
    drop:
      - ALL

# -- Nessie main service settings.
service:
  # -- The type of service to create.
  type: ClusterIP
  # -- The ports the service will listen on.
  # At least one port is required; the first port implicitly becomes the HTTP port that the
  # application will use for serving API requests. By default, it's 19120.
  # Note: port names must be unique and no more than 15 characters long.
  ports:
    - name: nessie-http
      number: 19120
    # - name: nessie-https
    #  number: 19121
  # -- The session affinity for the service. Valid values are: None, ClientIP.
  # ClientIP enables sticky sessions based on the client's IP address.
  # This is generally beneficial to Nessie deployments, but some testing may be
  # required in order to make sure that the load is distributed evenly among the pods.
  # Also, this setting affects only internal clients, not external ones.
  # If Ingress is enabled, it is recommended to set sessionAffinity to None.
  sessionAffinity: None
  # -- You can specify your own cluster IP address
  # If you define a Service that has the .spec.clusterIP set to "None" then Kubernetes does not assign an IP address.
  # Instead, DNS records for the service will return the IP addresses of each pod targeted by the server. This is
  # called a headless service.
  # See https://kubernetes.io/docs/concepts/services-networking/service/#headless-services
  clusterIP: ""
  # -- The traffic policy fields control how traffic from internal and external sources are routed respectively.
  # Valid values are Cluster and Local.
  # Set the field to Cluster to route traffic to all ready endpoints.
  # Set the field to Local to only route to ready node-local endpoints.
  # If the traffic policy is Local and there are no node-local endpoints, traffic is dropped by kube-proxy
  internalTrafficPolicy: Cluster
  externalTrafficPolicy: Cluster
  # -- The traffic distribution field provides another way to influence traffic routing within a Kubernetes Service.
  # While traffic policies focus on strict semantic guarantees, traffic distribution allows you to express preferences
  # such as routing to topologically closer endpoints.
  # Valid values are: PreferClose
  trafficDistribution: PreferClose
  # -- Annotations to add to the service.
  annotations: {}

# -- Management service settings. These settings are used to configure liveness and readiness probes,
# and to configure the dedicated headless service that will expose health checks and metrics, e.g.
# for metrics scraping and service monitoring.
managementService:
  # -- The name of the management port. Required.
  portName: nessie-mgmt
  # -- The port the management service listens on. By default, the management interface is exposed
  # on HTTP port 9000.
  portNumber: 9000
  # -- Annotations to add to the service.
  annotations: {}

# -- Additional service definitions. All service definitions always select all Nessie pods. Use
# this if you need to expose specific ports with different configurations.
extraServices: []
  #  - # -- The suffix to append to the service name. Required.
  #    nameSuffix: "-ext"
  #    # -- The type of service to create.
  #    type: LoadBalancer
  #    # -- The ports the service will listen on.
  #    ports:
  #    - name: nessie-http
  #      number: 19120
  #    - name: nessie-https
  #      number: 19121
  #    sessionAffinity: None
  #    clusterIP: ""
  #    internalTrafficPolicy: Cluster
  #    externalTrafficPolicy: Cluster
  #    trafficDistribution: PreferClose
  #    annotations: {}

# -- Nessie Ingress settings.
# These settings generate an Ingress resource that routes external traffic to the Nessie service.
# Consider enabling sticky sessions based on the remote client's IP address;
# this is generally beneficial to Nessie deployments, but some testing may be
# required in order to make sure that the load is distributed evenly among the pods.
# Check your ingress controller's documentation.
ingress:
  # -- Specifies whether an ingress should be created.
  enabled: true
  # -- Specifies the ingressClassName; leave empty if you don't want to customize it.
  className: "nginx"
  # -- Annotations to add to the ingress.
  annotations: {
    # nginx.ingress.kubernetes.io/upstream-hash-by: "$binary_remote_addr"
  }
  # -- Specifies the path type of host paths. Valid values are: "Prefix", "Exact" or "ImplementationSpecific".
  pathType: Prefix
  # -- A list of host paths used to configure the ingress.
  hosts:
    - host: nessie.172.30.1.101.nip.io
      paths:
        - /
      # -- The service target for the ingress.
      service:
        # -- The port name to route traffic to. Must match one of the ports in service.ports or in
        # extraServices.ports. Optional; if not provided, the first port in service.ports will be used.
        portName: nessie-http
        # -- The target service name suffix. Optional; if not provided, the main service will be
        # targeted. Change this only if you are targeting a service defined in extraServices.
        nameSuffix: ""
  # -- A list of TLS certificates; each entry has a list of hosts in the certificate,
  # along with the secret name used to terminate TLS traffic on port 443.
  tls: []
#    - hosts:
#        - chart-example1.local
#        - chart-example2.local
#      secretName: secret1

# -- Override the strategy for nessie deployment.
# Valid values for type are: RollingUpdate and Recreate.
# If you are using the ROCKSDB version store type then you should use Recreate.
# Max Surge will allow new pods to be created before old ones are culled. Do not enable this when using ROCKSDB
# version store type.
# Max Unavailable will allow old pods to be culled before replacements are created
# See: https://kubernetes.io/docs/concepts/workloads/controllers/deployment/#strategy
deploymentStrategy:
  {}
  # type: RollingUpdate
  # rollingUpdate:
  #   maxUnavailable: 0
  #   maxSurge: 1

# -- Configures the resources requests and limits for nessie pods.
# We usually recommend not to specify default resources and to leave this as a conscious
# choice for the user. This also increases chances charts run on environments with little
# resources, such as Minikube. If you do want to specify resources, uncomment the following
# lines, adjust them as necessary, and remove the curly braces after 'resources:'.
resources:
  {}
  # limits:
  #   cpu: 100m
  #   memory: 128Mi
  # requests:
  #   cpu: 100m
  #   memory: 128Mi

autoscaling:
  # -- Specifies whether automatic horizontal scaling should be enabled.
  # Do not enable this when using ROCKSDB version store type.
  enabled: false
  # -- The minimum number of replicas to maintain.
  minReplicas: 1
  # -- The maximum number of replicas to maintain.
  maxReplicas: 3
  # -- Optional; set to zero or empty to disable.
  targetCPUUtilizationPercentage: 80
  # -- Optional; set to zero or empty to disable.
  targetMemoryUtilizationPercentage:

# -- Node labels which must match for the nessie pod to be scheduled on that node. See https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#nodeselector.
nodeSelector:
  {}
  # kubernetes.io/os: linux

# -- A list of tolerations to apply to nessie pods. See https://kubernetes.io/docs/concepts/scheduling-eviction/taint-and-toleration/.
tolerations: []
#  - key: "node-role.kubernetes.io/control-plane"
#    operator: "Exists"
#    effect: "NoSchedule"

# -- Affinity and anti-affinity for nessie pods. See https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#affinity-and-anti-affinity.
affinity: {}
#  podAffinity:
#    preferredDuringSchedulingIgnoredDuringExecution:
#      - weight: 100
#        podAffinityTerm:
#          topologyKey: kubernetes.io/hostname
#          labelSelector:
#            matchExpressions:
#              - key: app.kubernetes.io/name
#                operator: In
#                values:
#                  - nessie

# -- Configures the liveness probe for nessie pods.
livenessProbe:
  # -- Number of seconds after the container has started before liveness probes are initiated. Minimum value is 0.
  initialDelaySeconds: 5
  # -- How often (in seconds) to perform the probe. Minimum value is 1.
  periodSeconds: 10
  # -- Minimum consecutive successes for the probe to be considered successful after having failed. Minimum value is 1.
  successThreshold: 1
  # -- Minimum consecutive failures for the probe to be considered failed after having succeeded. Minimum value is 1.
  failureThreshold: 3
  # -- Number of seconds after which the probe times out. Minimum value is 1.
  timeoutSeconds: 10
  # -- Optional duration in seconds the pod needs to terminate gracefully upon probe failure. Minimum value is 1.
  terminationGracePeriodSeconds: 30

# -- Configures the readiness probe for nessie pods.
readinessProbe:
  # -- Number of seconds after the container has started before readiness probes are initiated. Minimum value is 0.
  initialDelaySeconds: 5
  # -- How often (in seconds) to perform the probe. Minimum value is 1.
  periodSeconds: 10
  # -- Minimum consecutive successes for the probe to be considered successful after having failed. Minimum value is 1.
  successThreshold: 1
  # -- Minimum consecutive failures for the probe to be considered failed after having succeeded. Minimum value is 1.
  failureThreshold: 3
  # -- Number of seconds after which the probe times out. Minimum value is 1.
  timeoutSeconds: 10

# -- Extra volumes to add to the nessie pod. See https://kubernetes.io/docs/concepts/storage/volumes/.
extraVolumes: []
    # - name: extra-volume
    #   emptyDir: {}

# -- Extra volume mounts to add to the nessie container. See https://kubernetes.io/docs/concepts/storage/volumes/.
extraVolumeMounts: []
    # - name: extra-volume
    #   mountPath: /usr/share/extra-volume

# -- Add additional init containers to the nessie pod(s) See https://kubernetes.io/docs/concepts/workloads/pods/init-containers/.
extraInitContainers: []
    # - name: your-image-name
    #   image: your-image
    #   imagePullPolicy: Always
    #   command: ['sh', '-c', 'echo "hello world"']

# -- Add a PodDisruptionBudget. See https://kubernetes.io/docs/tasks/run-application/configure-pdb/.
podDisruptionBudget:
  enabled: false
  policy: {}
    #  maxUnavailable: 50%
    #  minAvailable: 50%
    #  unhealthyPodEvictionPolicy: AlwaysAllow
